# -*- coding: utf-8 -*-
"""k-means

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xRR8lbVFK2AoktfopDfVW_4aM8C9KL6W
"""
import subprocess
import sys

subprocess.check_call([sys.executable, "-m", "pip", "install", "scikit-plot"])


# Mengimpor pustaka yang diperlukan
import pandas as pd  # Untuk manipulasi data menggunakan DataFrames
import seaborn as sns  # Untuk visualisasi data statistik
import matplotlib.pyplot as plt  # Untuk membuat visualisasi statis, interaktif, dan animasi dalam Python
import numpy as np  # Untuk operasi numerik
from numpy import inf  # Mengimpor 'inf' (infinity) dari numpy
import scipy  # Untuk komputasi ilmiah
from scipy.stats import yeojohnson  # Untuk transformasi Yeojohnson
import scipy.stats as stats  # Fungsi statistik
from scipy.stats import jarque_bera  # Uji Jarque-Bera untuk normalitas
from scipy.stats import normaltest  # Uji normalitas D'Agostino dan Pearson
from scipy.stats import shapiro  # Uji Shapiro-Wilk untuk normalitas
import sklearn  # Untuk alat pembelajaran mesin
from sklearn import linear_model  # Model regresi linear
from sklearn.preprocessing import StandardScaler  # Standarisasi fitur dengan menghilangkan rata-rata dan penskalaan ke simpangan standar
from sklearn.preprocessing import MinMaxScaler  # Transformasi fitur dengan penskalaan setiap fitur ke rentang tertentu
from sklearn.model_selection import train_test_split, cross_val_score  # Membagi data dan validasi silang
from sklearn import metrics  # Metrik untuk mengevaluasi kinerja model
from sklearn.metrics import mean_absolute_error  # Metrik mean absolute error
from sklearn import preprocessing  # Pra-pemrosesan data
from sklearn.decomposition import PCA  # Analisis Komponen Utama
from sklearn.cluster import DBSCAN  # Klasterisasi berbasis kepadatan spasial aplikasi dengan noise
from sklearn.metrics import silhouette_score  # Skor Silhouette untuk evaluasi klasterisasi
from sklearn.cluster import KMeans  # Algoritma klasterisasi KMeans
from sklearn.metrics import silhouette_score  # Skor Silhouette untuk evaluasi klasterisasi
import plotly.express as px  # Pustaka visualisasi interaktif
import plotly.graph_objects as go  # Membuat dan mengubah grafik menggunakan antarmuka tingkat tinggi
import scikitplot as skplt  # Visualisasi untuk pembelajaran mesin
import statsmodels.api as sm  # Pustaka model statistik
from statsmodels.tools.eval_measures import mse, rmse  # Mean squared error dan root mean squared error
from statsmodels.tsa.stattools import acf  # Fungsi autocorrelation untuk analisis deret waktu
import tensorflow as tf  # Kerangka pembelajaran mesin sumber terbuka
from yellowbrick.cluster import KElbowVisualizer  # Visualizer untuk menemukan jumlah klaster yang optimal
import warnings  # Mengabaikan pesan peringatan selama eksekusi
import scikitplot


# Mengabaikan pesan peringatan pada keluaran
warnings.filterwarnings('ignore')

# Membaca data spotify dari file CSV menggunakan Pandas
df = pd.read_csv(r'spotify.csv')

"""### Memeriksa data"""

df.head()

# Menampilkan informasi tentang DataFrame, seperti tipe data dan jumlah nilai non-null
df.info()

# Menghitung jumlah nilai null (NaN) dalam setiap kolom DataFrame
df.isnull().sum()

# Mengidentifikasi dan mengekstrak baris yang merupakan duplikat dalam DataFrame
duplicates = df[df.duplicated()]

# Menampilkan baris duplikat
print("Baris Duplikat kecuali kemunculan pertama berdasarkan semua kolom:")
print(duplicates)

# Menampilkan jumlah baris dan kolom dalam DataFrame
df.shape

# Menampilkan ringkasan statistik deskriptif untuk kolom-kolom numerik dalam DataFrame
df.describe()

"""### Data Cleaning"""

# Kategori berikut tidak relevan, penelitian ini berkaitan dengan fitur apa yang membuat sebuah lagu "populer" di Spotify, bukan artis atau nama lagu atau albumnya yang mana
df = df.drop(['track_id', 'track_artist', 'track_album_name', 'track_name','track_album_id','playlist_id','track_album_release_date',
              'playlist_subgenre'], axis=1)

# Menampilkan lima baris pertama dalam DataFrame
df.head()

# Menampilkan jumlah baris dan kolom dalam DataFrame
df.shape

# Memfilter DataFrame df berdasarkan nilai kolom 'speechiness' yang kurang dari atau sama dengan 0.7
df = df[df['speechiness'] <= 0.7]

# Menampilkan informasi tentang DataFrame setelah proses filtering
df.info()

# Identifikasi kolom numerik dan kategorikal dalam DataFrame

numeric_cols = []  # Membuat list kosong untuk menampung nama kolom numerik
categorical_cols = []  # Membuat list kosong untuk menampung nama kolom kategorikal

# Iterasi melalui setiap kolom dalam DataFrame
for col in df.columns:
    # Memeriksa tipe data kolom, jika float64 atau int64, maka dianggap numerik
    if df[col].dtype == np.float64 or df[col].dtype == np.int64:
        numeric_cols.append(col)  # Menambahkan nama kolom numerik ke dalam list numeric_cols
    else:
        categorical_cols.append(col)  # Menambahkan nama kolom kategorikal ke dalam list categorical_cols

# Menampilkan hasil identifikasi kolom numerik dan kategorikal
print('Kolom numerik:', numeric_cols)
print('Kolom kategorikal:', categorical_cols)

# Memisahkan kolom numerik diskrit

# Membuat list discrete_numeric yang berisi nama kolom numerik yang memiliki kurang dari 20 nilai unik
discrete_numeric = [feature for feature in numeric_cols if df[feature].nunique() < 20]

# Menampilkan list kolom numerik diskrit
discrete_numeric

"""* Mode dan key akan diperlakukan sebagai fitur kategorikal, pengkodean label akan dilakukan."""

# Mengganti nilai dalam kolom 'mode': 0 dengan 'minor', 1 dengan 'major'
df['mode'] = df['mode'].replace({0: 'minor', 1: 'major'})

# Mengganti nilai dalam kolom 'key' dengan nama-nama kunci musik
df['key'] = df['key'].replace({
    0: 'C', 1: 'C-sharp_D-flat', 2: 'D', 3: 'D-sharp_E-flat',
    4: 'E', 5: 'F', 6: 'F-sharp_G-flat', 7: 'G',
    8: 'G-sharp_A-flat', 9: 'A', 10: 'A-sharp_B-flat', 11: 'B'
})

# Menghapus semua baris di mana "duration_ms" sama dengan 0
df = df[df['duration_ms'] != 0]

# Menampilkan lima baris pertama dalam DataFrame
df.head()

# Identifikasi kembali kolom numerik dan kategorikal setelah transformasi data

numeric_cols = []  # Membuat list kosong untuk menampung nama kolom numerik
categorical_cols = []  # Membuat list kosong untuk menampung nama kolom kategorikal

# Iterasi melalui setiap kolom dalam DataFrame yang sudah diubah
for col in df.columns:
    # Memeriksa tipe data kolom, jika float64 atau int64, maka dianggap numerik
    if df[col].dtype == np.float64 or df[col].dtype == np.int64:
        numeric_cols.append(col)  # Menambahkan nama kolom numerik ke dalam list numeric_cols
    else:
        categorical_cols.append(col)  # Menambahkan nama kolom kategorikal ke dalam list categorical_cols

# Menampilkan hasil identifikasi kolom numerik dan kategorikal setelah transformasi data
print('Kolom numerik:', numeric_cols)
print('Kolom kategorikal:', categorical_cols)

"""#### Checking for Outliers"""

# Memeriksa keberadaan outliers

max_rows = 50  # Batasi jumlah baris yang akan ditampilkan
# Menghitung Z-Score untuk setiap nilai dalam kolom numerik
z_scores = (df[numeric_cols] - df[numeric_cols].mean()) / df[numeric_cols].std()

# Mencari nilai absolut dari Z-Scores yang lebih besar dari threshold 3
threshold = 3
outliers = (z_scores.abs() > threshold).any(axis=1)

# Mendapatkan tata letak (style) dari outliers dan membatasi jumlah baris yang ditampilkan
outliers_style = df[outliers].style.background_gradient(cmap='Reds').set_table_attributes("style='display: table-row-group;'").set_caption(f"Outliers ({outliers.sum()} baris)")
outliers_html = outliers_style._repr_html_()

# Mendapatkan header tabel dan membatasi jumlah baris yang ditampilkan
header = df.head(0).style.set_table_attributes("style='display: none;'")._repr_html_()
data = df.head(max_rows if len(df) > max_rows else len(df)).style._repr_html_()

# Membuat box plot untuk setiap kolom dalam data numerik

# Mengatur subplot dengan satu baris dan jumlah kolom sesuai dengan jumlah kolom numerik
fig, axes = plt.subplots(nrows=1, ncols=len(numeric_cols), figsize=(28, 5))

# Membuat box plot untuk setiap kolom numerik
for i, col in enumerate(numeric_cols):
    axes[i].boxplot(df[col], vert=False)  # Membuat box plot dengan orientasi horizontal

    # Mengatur judul, label sumbu x, dan label sumbu y untuk setiap subplot
    axes[i].set_title(f"Boxplot of {col}")
    axes[i].set_xlabel("Feature Value")
    axes[i].set_ylabel(col)

# Menata layout subplot agar lebih rapi
fig.tight_layout()

# Menampilkan plot
plt.show()

# Menghitung persentase outliers untuk setiap fitur numerik melalui metode IQR

for col in numeric_cols:
    q1 = df[col].quantile(0.25)  # Kalkulasi kuartil pertama
    q3 = df[col].quantile(0.75)  # Kalkulasi kuartil ketiga
    iqr = q3 - q1  # Menghitung Interquartile Range (IQR)
    upper_boundary = q3 + 1.5 * iqr  # Batas atas untuk mengidentifikasi outliers
    lower_boundary = q1 - 1.5 * iqr  # Batas bawah untuk mengidentifikasi outliers
    outliers = df[(df[col] < lower_boundary) | (df[col] > upper_boundary)][col]  # Mengidentifikasi outliers
    outlier_percent = outliers.count() / df[col].count() * 100  # Menghitung persentase outliers
    print(f"{col} memiliki {outlier_percent:.2f}% outliers")

"""* Pencilan untuk "speechiness", "instrumentalness" tidak akan dihapus. Data ini terlalu penting dan dapat terjadi kesalahan jika ditangani. Misalnya memperlakukan "speechiness " dan "instrumental" dapat menghilangkan lagu rap di satu sisi dan klasik di sisi lain, yang keduanya memiliki komponen untuk membuat sebuah lagu menjadi populer.
<br>

* Fitur "duration_ms", "liveness", dan "loudness" akan diubah dengan metode Yeo-Johnson.
"""

# Mentransformasi beberapa kolom numerik menggunakan metode Yeojohnson

# Membuat salinan DataFrame
transformed_data = df.copy()

# Melakukan transformasi Yeojohnson pada kolom 'duration_ms', 'loudness', dan 'liveness'
transformed_data['duration_ms'], duration_lambda = yeojohnson(transformed_data['duration_ms'])
transformed_data['loudness'], loudness_lambda = yeojohnson(transformed_data['loudness'])
transformed_data['liveness'], loudness_lambda = yeojohnson(transformed_data['liveness'])

# Menampilkan ringkasan statistik deskriptif setelah transformasi
print(transformed_data[['duration_ms', 'loudness', 'liveness']].describe())

# Menghitung persentase outliers setelah transformasi Yeojohnson untuk beberapa fitur numerik

num_cols = ['track_popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']
df_num = transformed_data[num_cols]

for col in num_cols:
    q1 = transformed_data[col].quantile(0.25)  # Menghitung kuartil pertama
    q3 = transformed_data[col].quantile(0.75)  # Menghitung kuartil ketiga
    iqr = q3 - q1  # Menghitung Interquartile Range (IQR)
    upper_boundary = q3 + 1.5 * iqr  # Batas atas untuk mengidentifikasi outliers
    lower_boundary = q1 - 1.5 * iqr  # Batas bawah untuk mengidentifikasi outliers
    outliers = transformed_data[(transformed_data[col] < lower_boundary) | (transformed_data[col] > upper_boundary)][col]  # Mengidentifikasi outliers
    outlier_percent = outliers.count() / transformed_data[col].count() * 100  # Menghitung persentase outliers
    print(f"{col} memiliki {outlier_percent:.2f}% outliers")

"""* Yeo-Johnson mampu mengurangi persentase outlier dalam "loudness" lebih dari 50%.
<br>

* Persentase outlier untuk "liveness " dikurangi menjadi 0,0%.
<br>
* Persentase outlier pada fitur "duration_ms" tidak berkurang secara signifikan.
<br>
* Karena tujuan deteksi outlier adalah untuk mengidentifikasi nilai-nilai yang secara signifikan berada di luar distribusi umum data, maka pilihan biarkan data berada dalam pengganda IQR 1,5. Beberapa lagu hanya PANJANG.

#### Checking Numerical Features Distribution
"""

# Membuat salinan DataFrame hasil transformasi
df_t = transformed_data.copy()

# Menampilkan plot distribusi untuk fitur numerik setelah transformasi

n_cols = len(num_cols)
n_rows = int(np.ceil(n_cols / 3))

# Membuat subplot dengan jumlah baris dan kolom sesuai dengan jumlah fitur numerik
fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5 * n_rows))

# Melakukan iterasi melalui setiap fitur numerik dan membuat plot distribusi menggunakan Seaborn
for i, col in enumerate(num_cols):
    row_idx = i // 3
    col_idx = i % 3
    sns.distplot(df_t[col], ax=axes[row_idx, col_idx], kde=True)

    # Mengatur judul dan label sumbu x untuk setiap subplot
    axes[row_idx, col_idx].set_title(f"Distribution Plot of {col}")
    axes[row_idx, col_idx].set_xlabel(col)

# Menghapus subplot yang tidak terpakai jika jumlah fitur tidak habis dibagi 3
for i in range(n_cols, n_rows * 3):
    fig.delaxes(axes.flatten()[i])

# Menata layout subplot agar lebih rapi
fig.tight_layout()

# Menampilkan plot
plt.show()

# Melakukan uji Kolmogorov-Smirnov untuk mengecek distribusi normal pada setiap fitur numerik

data = df_t[['track_popularity', 'duration_ms', 'danceability', 'energy',
            'loudness', 'speechiness', 'acousticness', 'instrumentalness',
            'liveness', 'valence', 'tempo']]

# Melakukan iterasi melalui setiap kolom dan melakukan uji K-S
for col in data.columns:
    kstest_result = stats.kstest(data[col], 'norm')

    # Menampilkan nilai statistik uji dan nilai p untuk setiap kolom
    print(f"{col} - K-S test statistic:", kstest_result.statistic)
    print(f"{col} - p-value:", kstest_result.pvalue)

"""* Secara visual dan statistik (p-value < 0,05)  ada beberapa kolom numerik yang terdistribusi normal"""

# Mengecek apakah transformasi dapat menghasilkan distribusi yang lebih normal

num_cols = ['track_popularity', 'duration_ms', 'danceability', 'energy',
            'loudness', 'speechiness', 'acousticness', 'instrumentalness',
            'liveness', 'valence', 'tempo']

new_df = pd.DataFrame()

# Loop melalui setiap kolom dan transformasi yang mungkin
for col_name in num_cols:
    new_df[f'log({col_name})'] = np.log1p(df[col_name])  # Log transformasi
    new_df[f'sqrt({col_name})'] = np.sqrt(df[col_name])   # Square root transformasi
    new_df[f'exp({col_name})'] = np.exp(df[col_name])     # Exponential transformasi

plot_cols = 3

fig_width = 8
fig_height = 25
subplot_width = fig_width / plot_cols
subplot_height = fig_height / (len(num_cols) / plot_cols)

# Membuat subplot untuk setiap kolom dan transformasi dengan Seaborn
fig, axes = plt.subplots(len(num_cols), plot_cols, figsize=(fig_width, fig_height))

for i, col_name in enumerate(num_cols):
    for j, transform in enumerate(['log', 'sqrt', 'exp']):
        plot_data = new_df[f"{transform}({col_name})"]
        plot_title = f"{transform}({col_name})"
        ax = axes[i, j]
        sns.kdeplot(plot_data, ax=ax)
        ax.set_title(plot_title)

# Menyesuaikan spacing dan label
plt.tight_layout()
plt.subplots_adjust(hspace=0.6, wspace=0.3)
plt.show()

"""* Tidak ada satu pun dari transformasi yang secara visual tampak memberikan perbaikan besar pada fitur apa pun. Maka transformasi log, persegi, atau ekspodensial tidak akan dilakukan.

#### Data Exploration and Feature Engineering
"""

# Menampilkan beberapa baris pertama dari DataFrame df_t
df_t.head()

# Menghitung korelasi antar fitur numerik dan menampilkan sebagai heatmap

# Memilih kolom-kolom numerik dari DataFrame df_t
num_cols = df_t.select_dtypes(include=['int64', 'float64'])

# Menghitung matriks korelasi antar fitur numerik
corr_data = num_cols.corr()

# Membuat subplot heatmap
fig, ax = plt.subplots(figsize=(10, 10))

# Menampilkan heatmap dengan Annotasi (nilai korelasi ditampilkan pada sel heatmap)
sns.heatmap(corr_data, cmap="YlGnBu", annot=True)

# Menampilkan plot
plt.show()

"""* Tidak ada fitur berkelanjutan yang berkorelasi dengan target (track_popularity)
<br>
* loudness dan energi menunjukkan multikolinearitas (0,67). Karena "energi" adalah penilaian subjektif versus "loudness" yang diukur, energi akan dikeluarkan dari kumpulan data.
"""

# Menghapus kolom 'energy' dari DataFrame df_t
df_t = df_t.drop(['energy'], axis=1)

"""#### Checking the Balance of Categorical Features"""

# Identifikasi kolom-kolom kontinu dan kategorikal dalam DataFrame df_t

# Inisialisasi list untuk kolom-kolom kontinu dan kategorikal
continuous_cols = []
categorical_cols = []

# Iterasi melalui setiap kolom dalam DataFrame df_t
for col in df_t.columns:
    # Memeriksa tipe data kolom (float64 atau int64)
    if df_t[col].dtype == np.float64 or df_t[col].dtype == np.int64:
        continuous_cols.append(col)  # Jika tipe data adalah numerik, tambahkan ke kolom kontinu
    else:
        categorical_cols.append(col)  # Jika tipe data bukan numerik, tambahkan ke kolom kategorikal

# Menampilkan hasil identifikasi
print('Continuous columns:', continuous_cols)
print('Categorical columns:', categorical_cols)

# Menampilkan countplot untuk setiap kolom kategorikal dalam DataFrame df_t

# Iterasi melalui setiap kolom kategorikal
for column in categorical_cols:
    # Membuat figure dengan ukuran tertentu
    plt.figure(figsize=(16, 6))

    # Menggunakan Seaborn untuk membuat countplot
    sns.countplot(x=column, data=df_t.loc[:, categorical_cols])

    # Menambahkan judul plot
    plt.title(column)

"""* All categorical features are unbalanced."""

# Menampilkan barplot rata-rata 'track_popularity' untuk setiap nilai unik dalam setiap kolom kategorikal dalam DataFrame df_t

# Iterasi melalui setiap kolom kategorikal
for column in categorical_cols:
    # Membuat salinan DataFrame df_t
    dataset = df_t.copy()

    # Membuat figure dengan ukuran tertentu
    plt.figure(figsize=(16, 6))

    # Menggunakan Seaborn untuk membuat barplot rata-rata 'track_popularity'
    sns.barplot(x=column, y=dataset['track_popularity'], data=dataset, estimator=np.mean)

    # Menampilkan plot
    plt.show()

"""* Lagu dengan genre pop memiliki skor popularitas lebih tinggidibandingkan dengan 5 genre lainnya.
<br>

* Skor popularitas utama serupa, namun G-sharp_A-flat memimpin.
<br>
* Minor tampaknya hampir tidak mempunyai keunggulan dalam skor popularitas. Jauh lebih banyak lagu yang masuk dalam mayor tetapi minor mendapat keunggulan dalam popularitas.
<br>
* playlist_name terlalu banyak sehingga plotnya tidak bisa menentukan siapa pemenangnya.
"""

# Menghitung rata-rata popularitas lagu untuk setiap genre playlist dan menampilkan lima genre teratas

# Menggunakan groupby untuk menghitung rata-rata popularitas lagu untuk setiap genre playlist
top_five_genres = df_t.groupby("playlist_genre")["track_popularity"].mean().nlargest(5)

# Membuat DataFrame baru dengan lima genre teratas dan rata-rata popularitas mereka
table = pd.DataFrame({'playlist_genre': top_five_genres.index, 'mean_popularity': top_five_genres.values}).set_index('playlist_genre')

# Menampilkan tabel hasil
print(table)

"""* Genre pop mengungguli genre latin       dalam skor popularitas rata-rata."""

# Menghapus kolom 'playlist_genre' dari DataFrame df_t
df_t = df_t.drop(['playlist_genre'], axis=1)

# Menampilkan informasi tentang DataFrame df_t
df_t.info()

# Menghitung jumlah baris, kolom, dan total sampel dalam DataFrame df_t

# Menghitung jumlah baris dalam DataFrame df_t
num_rows = df_t.shape[0]

# Menghitung jumlah kolom dalam DataFrame df_t
num_col = df_t.shape[1]

# Menghitung total sampel (baris * kolom) dalam DataFrame df_t
total_samples = num_rows * num_col

# Menampilkan hasil perhitungan
print('Number of rows:', num_rows)
print('Number of columns:', num_col)
print('Total number of samples:', total_samples)

"""### Modeling

* Pertama-tama tentukan K untuk clustering KMeans.
<br>
* Diikuti dengan menjalankan model pengelompokan KMeans menggunakan TensorFlow dan Pycaret untuk menentukan pola dan/atau hubungan apa pun dalam data.
"""

# Memilih kolom-kolom numerik tertentu dan melakukan penskalaan

# Kolom-kolom yang akan diambil
num_cols = ["duration_ms", "tempo", "loudness", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "danceability"]

# Membuat salinan DataFrame df_t dengan hanya mempertahankan kolom-kolom numerik tertentu
df_scaled = df_t[num_cols].copy()

# Menerapkan penskalaan pada kolom-kolom terpilih menggunakan StandardScaler
scaler = StandardScaler()
df_scaled[num_cols] = scaler.fit_transform(df_scaled)

# Menghitung WCSS (Within-Cluster-Sum-of-Squares) untuk nilai k yang berbeda
wcss = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(df_scaled)
    wcss.append(kmeans.inertia_)

# Menampilkan grafik Elbow Method
plt.plot(range(2, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

# Menampilkan Elbow Method menggunakan KElbowVisualizer

# Membuat objek model KMeans
model = KMeans()

# Membuat objek KElbowVisualizer dengan k dari 2 hingga 10
visualizer = KElbowVisualizer(model, k=(2, 10))

# Menyesuaikan visualizer dengan data yang telah di-skala
visualizer.fit(df_scaled)

# Menampilkan plot Elbow Method
visualizer.show()

# Melakukan clustering menggunakan KMeans dengan 5 cluster dan menampilkan plot Silhouette score

# Membuat objek KMeans dengan 5 cluster
kmeans = KMeans(n_clusters=5)

# Melakukan clustering pada data yang telah di-skala
kmeans.fit(df_scaled)

# Menampilkan plot Silhouette score per cluster
skplt.metrics.plot_silhouette(df_scaled,
                                kmeans.labels_,
                                title='Silhouette score per cluster',
                                figsize=(12, 8))
plt.show()

# Melakukan clustering menggunakan KMeans dengan 6 cluster dan menampilkan plot Silhouette score

# Membuat objek KMeans dengan 6 cluster
kmeans = KMeans(n_clusters=6)

# Melakukan clustering pada data yang telah di-skala
kmeans.fit(df_scaled)

# Menampilkan plot Silhouette score per cluster
skplt.metrics.plot_silhouette(df_scaled,
                                kmeans.labels_,
                                title='Silhouette score per cluster',
                                figsize=(12, 8))
plt.show()

# Melakukan clustering menggunakan KMeans dengan 7 cluster dan menampilkan plot Silhouette score

# Membuat objek KMeans dengan 7 cluster
kmeans = KMeans(n_clusters=7)

# Melakukan clustering pada data yang telah di-skala
kmeans.fit(df_scaled)

# Menampilkan plot Silhouette score per cluster
skplt.metrics.plot_silhouette(df_scaled,
                                kmeans.labels_,
                                title='Silhouette score per cluster',
                                figsize=(12, 8))
plt.show()

"""* Semua skor Silhoutte dan grafik siku menunjukkan bahwa titik data mungkin tumpang tindih atau dipisahkan dengan buruk ke dalam kelompok yang berbeda.
* Kmeans akan dicoba dengan n_clusters=6
"""

# Menggunakan algoritma KMeans untuk mengelompokkan data menggunakan TensorFlow KMeans

# Membuat objek KMeans dengan TensorFlow
kmeans = tf.compat.v1.estimator.experimental.KMeans(
    num_clusters=6,
    use_mini_batch=False,
)

# Mendefinisikan fungsi input
def input_fn():
    return tf.compat.v1.train.limit_epochs(
        tf.convert_to_tensor(df_scaled.values, dtype=tf.float32), num_epochs=1)

# Melatih model KMeans pada data
kmeans.train(input_fn)

# Memprediksi indeks kluster untuk setiap data
cluster_ids = list(kmeans.predict_cluster_index(input_fn))

# Menambahkan kolom 'cluster_id' ke DataFrame df_scaled
df_scaled['cluster_id'] = cluster_ids

# Menghitung pusat kluster
with tf.compat.v1.Session() as sess:
    sess.run(tf.compat.v1.global_variables_initializer())
    sess.run(tf.compat.v1.tables_initializer())
    centroids = kmeans.cluster_centers()

# Menampilkan histogram dari penugasan kluster

# Menggunakan Seaborn untuk membuat countplot
sns.countplot(data=df_scaled, x='cluster_id')

# Menambahkan judul dan label pada plot
plt.title('Histogram of Cluster Assignments')
plt.xlabel('Cluster')
plt.ylabel('Count')

# Menampilkan plot
plt.show()

# Membuat objek trace untuk plot 3D Scatter
trace = go.Scatter3d(
    x=df_t['duration_ms'],
    y=df_t['loudness'],
    z=df_t['tempo'],
    mode='markers',
    marker=dict(
        size=12,
        color=df_scaled['cluster_id'],
        colorscale='Viridis',
        opacity=0.8)
)

# Mendefinisikan layout plot
layout = go.Layout(
    scene=dict(
        xaxis_title='Duration_ms',
        yaxis_title='Loudness',
        zaxis_title='Tempo'
    ),
    title='3D Scatter Plot of Clusters',
    width=800,
    height=600,
)

# Membuat objek Figure
fig = go.Figure(data=[trace], layout=layout)

# Menampilkan plot menggunakan plotly
fig.show()

!pip install pycaret

# Pengaturan clustering menggunakan PyCaret

# Mengimpor modul dan fungsi yang diperlukan dari pycaret
import pycaret
from pycaret.clustering import *

# Menyiapkan pengaturan clustering dengan PyCaret
clustering_setup = setup(df_scaled, preprocess=False, use_gpu=True)

# Membuat model KMeans dengan PyCaret
kmeans_model = create_model('kmeans', num_clusters=6)

# Menugaskan hasil kluster ke dataset
kmeans_results = assign_model(kmeans_model)

# Menampilkan plot dari model KMeans
plot_model(kmeans_model, 'cluster')

# Menampilkan hasil kluster untuk setiap data
print(kmeans_results)

"""* Model TensorFlow dan Pycaret menunjukkan bahwa datanya padat dan tumpang tindih.
* PCA selanjutnya akan digunakan untuk menentukan fitur yang paling relevan dari fitur numerik.
"""

# Analisis PCA (Principal Component Analysis)

# Membuat objek PCA dengan 5 komponen utama
pca = PCA(n_components=5)

# Melatih model PCA dengan data yang telah di-skala
pca.fit(df_scaled)

# Mengtransformasikan data ke ruang fitur PCA
df_pca = pca.transform(df_scaled)

# Menghitung rasio varians yang dijelaskan oleh setiap komponen
variance_ratio = pca.explained_variance_ratio_

# Menghitung kumulatif rasio varians
cumulative_variance_ratio = np.cumsum(variance_ratio)

# Menampilkan plot kumulatif rasio varians vs. jumlah komponen utama
plt.plot(cumulative_variance_ratio)
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Variance Ratio')
plt.title('Cumulative Variance vs. Number of Principal Components')
plt.show()

# Menampilkan rasio varians untuk setiap komponen utama
for i in range(len(variance_ratio)):
    print(f"PC{i+1} explains {variance_ratio[i]*100:.2f}% of the variance in the data")

# Mengambil nama fitur yang paling penting
important_features = [x for _, x in sorted(zip(variance_ratio, num_cols), reverse=True)]

# Print the names of the most important features
print('The most important features are:', important_features)
